# Convo-AI

A conversational AI project optimized for Mac M-series chips, using free and local tools.

![Test Status](https://github.com/calummallorie/convo-ai/actions/workflows/test.yml/badge.svg) ![Coverage](https://img.shields.io/badge/coverage-88%25-green) [![Test Coverage](https://img.shields.io/badge/coverage-88%25-green)](https://gist.github.com/CalumMallorie/0ced90b88d93397be075cdf0cbb8cf03)

## Features

- LLM client with streaming support
- Text-to-Speech with MPS optimization
- Comprehensive test suite with CI integration
- Optimized for Mac M-series chips

## Setup

1. Clone the repository:
```bash
git clone https://github.com/calummallorie/convo-ai.git
cd convo-ai
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Run the tests:
```bash
python -m pytest
```

## Test Coverage

This project maintains a high test coverage (currently 89%). You can generate a coverage report by running:

```bash
python scripts/run_coverage.py
```

This will:
- Run all tests with coverage
- Generate HTML and XML coverage reports
- Update the coverage Gist (if configured)
- Generate a coverage badge

The coverage reports will be available in the `reports/coverage/html` directory.

## Automated Testing

This project uses GitHub Actions for automated testing. Every time you push code or create a pull request, the tests will run automatically.

The CI environment is configured to:
- Run tests with coverage
- Mock external services (LLM, TTS) to ensure tests pass consistently
- Provide a coverage report

To see the test results:
1. Go to your repository on GitHub
2. Click on the "Actions" tab
3. Click on any workflow run to see the results

## Project Roadmap

### Completed
- âœ… LLM client with streaming support 
- âœ… TTS client with MPS optimization
- âœ… Comprehensive test suite
- âœ… Configuration system
- âœ… CI integration with GitHub Actions
- âœ… Test coverage reporting (89%)
- âœ… Mock LLM service in CI

### In Progress
- ðŸ”„ Performance benchmarks
- ðŸ”„ Demo scripts

### Planned
- ðŸ“… Enhance documentation
- ðŸ“… Implement caching for LLM responses
- ðŸ“… Add support for audio input (speech-to-text)

## Project Structure

```
convo-ai/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/        # GitHub Actions workflows
â”œâ”€â”€ scripts/              # Utility scripts
â”‚   â”œâ”€â”€ run_coverage.py   # Run tests with coverage
â”‚   â”œâ”€â”€ create_coverage_gist.py
â”‚   â”œâ”€â”€ update_coverage_gist.py
â”‚   â””â”€â”€ generate_coverage_badge.py
â”œâ”€â”€ src/                  # Source code
â”œâ”€â”€ tests/                # Test files
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ pytest.ini           # Pytest configuration
â””â”€â”€ README.md            # This file
```

## Contributing

1. Create a new branch for your changes
2. Make your changes
3. Run the tests to make sure everything works
4. Create a pull request

## License

This project is licensed under the MIT License - see the LICENSE file for details. 